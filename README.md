# ğŸ¬ AnÃ¡lisis de la Industria CinematogrÃ¡fica - Proyecto ETL con Apache Airflow

## ğŸ“€ Autor: Alejandro Arteaga Jaramillo

## ğŸ“š DescripciÃ³n del Proyecto

Este proyecto implementa un pipeline **ETL (ExtracciÃ³n, TransformaciÃ³n y Carga)** automatizado con **Apache Airflow** para analizar la evoluciÃ³n de la industria cinematogrÃ¡fica. AdemÃ¡s, se realiza un **AnÃ¡lisis Exploratorio de Datos (EDA)** y se presentan visualizaciones en **Grafana**.

El objetivo es identificar patrones de Ã©xito en las pelÃ­culas, analizar la evoluciÃ³n de preferencias del pÃºblico y evaluar la influencia del presupuesto en el rendimiento comercial.

---

## ğŸ¯ Problema y Contexto

La industria del cine ha cambiado significativamente debido a avances tecnolÃ³gicos y el auge del streaming. Este proyecto busca responder preguntas clave:

âœ”ï¸ Â¿QuÃ© factores influyen en el Ã©xito de una pelÃ­cula?  
âœ”ï¸ Â¿CÃ³mo han cambiado las preferencias del pÃºblico a lo largo del tiempo?  
âœ”ï¸ Â¿CÃ³mo afectan el presupuesto y la estrategia de lanzamiento al rendimiento comercial?  
âœ”ï¸ Â¿CÃ³mo han evolucionado las crÃ­ticas y la percepciÃ³n del pÃºblico?  

---

## ğŸ“‚ DescripciÃ³n del Dataset

El dataset **"Full IMDb Movies Data"** contiene informaciÃ³n detallada sobre pelÃ­culas desde 1990 hasta la actualidad.

ğŸ“€ **Variables principales:**  
`id`, `title`, `vote_average`, `vote_count`, `status`, `release_date`, `revenue`, `runtime`, `adult`, `budget`, `imdb_id`, `original_language`, `genres`, `production_companies`, `keywords`, entre otros.

ğŸ“€ **Registros:**  
903,263 filas originales, reducidas a ~98,000 para mejorar la eficiencia del anÃ¡lisis.

---

## ğŸ”„ Proceso ETL con Apache Airflow

### ğŸ’¡ Arquitectura

El proceso ETL se gestiona mediante **Apache Airflow**, utilizando DAGs para orquestar las tareas.

- **ExtracciÃ³n:** Descarga de datos desde Kaggle y APIs externas.
- **TransformaciÃ³n:** Limpieza de datos con Pandas y generaciÃ³n de nuevas variables.
- **Carga:** InserciÃ³n de datos en PostgreSQL para su anÃ¡lisis y visualizaciÃ³n en Grafana.

### ğŸ”¹ Estructura del DAG

```plaintext
etl_movies_dag
|
|-- task_extract_data  (Extrae los datos de Kaggle)
|-- task_transform_data (Limpia y procesa los datos con Pandas)
|-- task_load_data (Carga los datos en PostgreSQL)
|-- task_validate_data (Ejecuta validaciones sobre los datos cargados)
```

### ğŸ”¹ Archivos clave

- `dags/etl_movies.py` - Define el DAG y sus tareas.
- `scripts/extract.py` - Maneja la extracciÃ³n de datos.
- `scripts/transform.py` - Realiza la limpieza y transformaciÃ³n.
- `scripts/load.py` - Inserta los datos en PostgreSQL.

---

## ğŸ“Š VisualizaciÃ³n con Grafana

Los datos procesados se visualizan en **Grafana**, permitiendo el anÃ¡lisis de:

- **DistribuciÃ³n de pelÃ­culas por gÃ©nero**.
- **Puntuaciones promedio por gÃ©nero**.
- **Presupuesto promedio por gÃ©nero**.
- **ComparaciÃ³n de rentabilidad de pelÃ­culas**.

Los dashboards se conectan a la base de datos PostgreSQL para extraer los datos en tiempo real.

---

## ğŸ› ï¸ InstalaciÃ³n y EjecuciÃ³n

### ğŸ‘‰ Prerrequisitos

- **Python 3.8+**
- **Apache Airflow 2.7+**
- **PostgreSQL 14+**
- **Grafana**

### ğŸ‘‰ ConfiguraciÃ³n de Carpetas y Rutas

Antes de ejecutar Airflow o los scripts, es necesario:

1. **Crear la carpeta `config/`** y colocar dentro el archivo `kaggle.json` para autenticar la descarga de datos.
2. **Crear la carpeta `data/`** donde se almacenarÃ¡ el dataset descargado y procesado.
3. **Configurar la ruta de trabajo** en Airflow y en los scripts ETL para que apunten a las carpetas correctas.

### ğŸ‘‰ InstalaciÃ³n

```bash
# Clonar el repositorio
git clone https://github.com/alejandroarteagaj/ETL_PROYECT_MOVIE_DATA.git
cd ETL_PROYECT_MOVIE_DATA

# Crear y activar entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

### ğŸ‘‰ Ejecutar Apache Airflow

```bash
# Inicializar la base de datos de Airflow
airflow db init

# Crear un usuario administrador
airflow users create \
    --username admin \
    --firstname Alejandro \
    --lastname Arteaga \
    --role Admin \
    --email admin@example.com

# Iniciar el scheduler y webserver
airflow scheduler &
airflow webserver &
```

### ğŸ‘‰ Ejecutar el DAG ETL en Airflow

1. Abre Airflow en el navegador: [http://localhost:8080](http://localhost:8080).
2. Habilita y ejecuta el DAG `etl_movies_dag`.
3. Verifica la carga de datos en PostgreSQL.

---

## ğŸ“© Contacto
ğŸ“Œ Alejandro Arteaga Jaramillo
ğŸ”— LinkedIn | ğŸ™ GitHub | âœ‰ï¸ Email


